{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "pb6_wSDwPo5r"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/cvgl/anaconda3/envs/haad/lib/python3.11/site-packages/pl_bolts/__init__.py:11: FutureWarning: In the future `np.object` will be defined as the corresponding NumPy scalar.\n",
            "  if not hasattr(numpy, tp_name):\n",
            "/home/cvgl/anaconda3/envs/haad/lib/python3.11/site-packages/pl_bolts/__init__.py:11: FutureWarning: In the future `np.bool` will be defined as the corresponding NumPy scalar.\n",
            "  if not hasattr(numpy, tp_name):\n",
            "/home/cvgl/anaconda3/envs/haad/lib/python3.11/site-packages/pl_bolts/models/self_supervised/amdim/amdim_module.py:34: UnderReviewWarning: The feature generate_power_seq is currently marked under review. The compatibility with other Lightning projects is not guaranteed and API may change at any time. The API and functionality may change without warning in future releases. More details: https://lightning-bolts.readthedocs.io/en/latest/stability.html\n",
            "  \"lr_options\": generate_power_seq(LEARNING_RATE_CIFAR, 11),\n",
            "/home/cvgl/anaconda3/envs/haad/lib/python3.11/site-packages/pl_bolts/models/self_supervised/amdim/amdim_module.py:92: UnderReviewWarning: The feature FeatureMapContrastiveTask is currently marked under review. The compatibility with other Lightning projects is not guaranteed and API may change at any time. The API and functionality may change without warning in future releases. More details: https://lightning-bolts.readthedocs.io/en/latest/stability.html\n",
            "  contrastive_task: Union[FeatureMapContrastiveTask] = FeatureMapContrastiveTask(\"01, 02, 11\"),\n",
            "/home/cvgl/anaconda3/envs/haad/lib/python3.11/site-packages/pl_bolts/losses/self_supervised_learning.py:228: UnderReviewWarning: The feature AmdimNCELoss is currently marked under review. The compatibility with other Lightning projects is not guaranteed and API may change at any time. The API and functionality may change without warning in future releases. More details: https://lightning-bolts.readthedocs.io/en/latest/stability.html\n",
            "  self.nce_loss = AmdimNCELoss(tclip)\n",
            "/home/cvgl/anaconda3/envs/haad/lib/python3.11/site-packages/albumentations/__init__.py:13: UserWarning: A new version of Albumentations is available: 1.4.21 (you have 1.4.14). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.\n",
            "  check_for_updates()\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import Dataset\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "from lightning import LightningModule, Trainer, LightningDataModule\n",
        "from collections import OrderedDict\n",
        "from PIL import Image\n",
        "from glob import glob\n",
        "import joblib\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import faiss\n",
        "from tqdm import tqdm\n",
        "from torchvision import transforms\n",
        "from fastervit import create_model\n",
        "import timm\n",
        "from torch.cuda.amp import autocast\n",
        "from pl_bolts.optimizers.lr_scheduler import LinearWarmupCosineAnnealingLR\n",
        "from distill_transforms import get_transforms_val\n",
        "DIM = 1024"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "prob_rotate: float = 0.75          # rotates the sat image and ground images simultaneously\n",
        "prob_flip: float = 0.5             # flipping the sat image and ground images simultaneously\n",
        "student_sat_size: tuple = (384, 384)\n",
        "student_street_size: tuple = (384, 768)\n",
        "\n",
        "sat_transforms_val_student, street_transforms_val_student = get_transforms_val(student_sat_size, student_street_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "k8yh-l3QgiDC"
      },
      "outputs": [],
      "source": [
        "class WeightDistillEvalSet(Dataset):\n",
        "    def __init__(self, img_type = 'reference', same_area = True):\n",
        "        \n",
        "        self.same_area = same_area\n",
        "        self.img_type = img_type\n",
        "        \n",
        "        self.cities = []\n",
        "        \n",
        "        if same_area:\n",
        "            self.cities = ['Chicago', 'NewYork', 'SanFrancisco', 'Seattle']\n",
        "        else:\n",
        "            self.cities = ['Chicago', 'SanFrancisco'] \n",
        "               \n",
        "        # load sat list \n",
        "        sat_list = []\n",
        "        for city in self.cities:\n",
        "            df_tmp = pd.read_csv(f'VIGOR/splits/{city}/satellite_list.txt', header=None, sep='\\s+')\n",
        "            df_tmp = df_tmp.rename(columns={0: \"sat\"})\n",
        "            df_tmp[\"path\"] = df_tmp.apply(lambda x: f'VIGOR/{city}/satellite/{x.sat}', axis=1)\n",
        "            sat_list.append(df_tmp)\n",
        "        self.df_sat = pd.concat(sat_list, axis=0).reset_index(drop=True)\n",
        "        \n",
        "        # idx for complete train and test independent of mode = train or test\n",
        "        sat2idx = dict(zip(self.df_sat.sat, self.df_sat.index))\n",
        "        self.idx2sat = dict(zip(self.df_sat.index, self.df_sat.sat))\n",
        "        self.idx2sat_path = dict(zip(self.df_sat.index, self.df_sat.path))\n",
        "        \n",
        "        \n",
        "        # ground dependent on mode 'train' or 'test'\n",
        "        ground_list = []\n",
        "        for city in self.cities:\n",
        "            \n",
        "            if same_area:\n",
        "                df_tmp = pd.read_csv(f'VIGOR/splits/{city}/cross_area_balanced_test.txt', header=None, sep='\\s+')\n",
        "            else:\n",
        "                df_tmp = pd.read_csv(f'VIGOR/splits/{city}/pano_label_balanced.txt', header=None, sep='\\s+')\n",
        "  \n",
        "            \n",
        "            df_tmp = df_tmp.loc[:, [0, 1, 4, 7, 10]].rename(columns={0:  \"ground\",\n",
        "                                                                     1:  \"sat\",\n",
        "                                                                     4:  \"sat_np1\",\n",
        "                                                                     7:  \"sat_np2\",\n",
        "                                                                     10: \"sat_np3\"})\n",
        "            \n",
        "            df_tmp[\"path_ground\"] = df_tmp.apply(lambda x: f'VIGOR/{city}/panorama/{x.ground}', axis=1)\n",
        "            df_tmp[\"path_sat\"] = df_tmp.apply(lambda x: f'VIGOR/{city}/satellite/{x.sat}', axis=1)\n",
        "            \n",
        "            df_tmp[\"path_sat_np1\"] = df_tmp.apply(lambda x: f'VIGOR/{city}/satellite/{x.sat_np1}', axis=1)\n",
        "            df_tmp[\"path_sat_np2\"] = df_tmp.apply(lambda x: f'VIGOR/{city}/satellite/{x.sat_np2}', axis=1)\n",
        "            df_tmp[\"path_sat_np3\"] = df_tmp.apply(lambda x: f'VIGOR/{city}/satellite/{x.sat_np3}', axis=1)\n",
        "\n",
        "            \n",
        "            for sat_n in [\"sat\", \"sat_np1\", \"sat_np2\", \"sat_np3\"]:\n",
        "                df_tmp[f'{sat_n}'] = df_tmp[f'{sat_n}'].map(sat2idx)\n",
        "                \n",
        "            ground_list.append(df_tmp) \n",
        "        self.df_ground = pd.concat(ground_list, axis=0).reset_index(drop=True)\n",
        "        \n",
        "        # idx for split train or test dependent on mode = train or test\n",
        "        self.idx2ground = dict(zip(self.df_ground.index, self.df_ground.ground))\n",
        "        self.idx2ground_path = dict(zip(self.df_ground.index, self.df_ground.path_ground))\n",
        "        \n",
        "        \n",
        "        if self.img_type == \"reference\":\n",
        "            # all sat images of cities in split\n",
        "            self.images = self.df_sat[\"path\"].values\n",
        "            self.label = self.df_sat.index.values\n",
        "            \n",
        "        else: #img_type == \"query\":\n",
        "            self.images = self.df_ground[\"path_ground\"].values\n",
        "            self.label = self.df_ground[[\"sat\", \"sat_np1\", \"sat_np2\", \"sat_np3\"]].values\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.images)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path = self.images[idx]\n",
        "        label = self.label[idx]\n",
        "\n",
        "        # Open and process the image\n",
        "        with Image.open(img_path).convert('RGB') as img:\n",
        "            if self.img_type == 'reference':\n",
        "                img = sat_transforms_val_student(image= np.asarray(img))['image']\n",
        "            else:\n",
        "                img = street_transforms_val_student(image= np.asarray(img))['image']\n",
        "        \n",
        "        return label, img\n",
        "\n",
        "# Usage\n",
        "query_set = WeightDistillEvalSet(img_type= 'query', same_area= False)\n",
        "reference_set = WeightDistillEvalSet(img_type= 'reference', same_area= False)\n",
        "\n",
        "query_loader = torch.utils.data.DataLoader(query_set, batch_size= 64, num_workers = 8, shuffle=False, drop_last=False)\n",
        "reference_loader = torch.utils.data.DataLoader(reference_set, batch_size= 64, num_workers = 8, shuffle=False, drop_last=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [],
      "source": [
        "# class ContrastiveModel(LightningModule):\n",
        "#     def __init__(self):\n",
        "#         super().__init__()\n",
        "\n",
        "#         # self.teacher_model = TimmModel('convnext_base.fb_in22k_ft_in1k_384', pretrained=True, img_size= 384)\n",
        "#         # self.teacher_model.load_state_dict(torch.load(\"pretrained/cvact/convnext_base.fb_in22k_ft_in1k_384/weights_e36_90.8149.pth\", weights_only=True))\n",
        "#         # self.teacher_model.eval()\n",
        "#         # for param in self.teacher_model.parameters():\n",
        "#         #     param.requires_grad = False\n",
        "            \n",
        "#         self.sat_model = create_model('faster_vit_0_224', pretrained=True, model_path=\"/tmp/faster_vit_0.pth.tar\")\n",
        "#         self.sat_linear = nn.Linear(1000, 1024)\n",
        "        \n",
        "#         self.street_model = create_model('faster_vit_0_224', pretrained=True, model_path=\"/tmp/faster_vit_0.pth.tar\")\n",
        "#         self.street_linear = nn.Linear(1000, 1024)\n",
        "        \n",
        "#         self.loss = nn.CosineEmbeddingLoss()\n",
        "\n",
        "#     def forward(self, teacher_sat_feat, teacher_street_feat, stud_sat_feat, stud_street_feat):\n",
        "#         student_sat_features = self.sat_linear(self.sat_model(stud_sat_feat))\n",
        "#         student_street_features = self.street_linear(self.street_model(stud_street_feat))\n",
        "        \n",
        "#         # with autocast():\n",
        "#         #     teacher_sat_features = self.teacher_model(teacher_sat_feat)\n",
        "#         #     teacher_street_features = self.teacher_model(teacher_street_feat)\n",
        "        \n",
        "#         loss_sat = self.loss(student_sat_features, teacher_sat_features, torch.ones(student_sat_features.shape[0], device= self.device))\n",
        "#         loss_street = self.loss(student_street_features, teacher_street_features, torch.ones(student_street_features.shape[0], device= self.device))\n",
        "        \n",
        "#         return (loss_sat + loss_street) / 2\n",
        "\n",
        "    \n",
        "#     def training_step(self, batch, batch_idx):\n",
        "#         teacher_sat_feat, teacher_street_feat, stud_sat_feat, stud_street_feat = batch\n",
        "#         loss = self(teacher_sat_feat, teacher_street_feat, stud_sat_feat, stud_street_feat)\n",
        "\n",
        "#         #n = logits.size(0)\n",
        "\t\n",
        "#         # -1 for off-diagonals and 1 for diagonals\n",
        "#         #labels = 2 * torch.eye(n, device=logits.device) - 1\n",
        "        \n",
        "#         # pairwise sigmoid loss\n",
        "#         #loss= -torch.sum(F.logsigmoid(labels * logits)) / n\n",
        "    \n",
        "#         self.log(\"train_loss\", loss.item(), on_step=True, on_epoch=True, prog_bar=True, logger=True)\n",
        "        \n",
        "#         return loss\n",
        "\n",
        "#     def validation_step(self, batch, batch_idx):\n",
        "#         teacher_sat_feat, teacher_street_feat, stud_sat_feat, stud_street_feat = batch\n",
        "#         loss = self(teacher_sat_feat, teacher_street_feat, stud_sat_feat, stud_street_feat)\n",
        "\n",
        "#         #n = logits.size(0)\n",
        "\t\n",
        "#         # # -1 for off-diagonals and 1 for diagonals\n",
        "#         #labels = 2 * torch.eye(n, device=logits.device) - 1\n",
        "        \n",
        "#         # # pairwise sigmoid loss\n",
        "#         #loss= -torch.sum(F.logsigmoid(labels * logits)) / n\n",
        "\n",
        "#         self.log(\"val_loss\", loss.item(), on_step=True, on_epoch=True, prog_bar=True, logger=True)\n",
        "            \n",
        "#     def configure_optimizers(self):\n",
        "#         optimizer = torch.optim.AdamW(self.parameters(), lr= 1e-4)\n",
        "#         scheduler = LinearWarmupCosineAnnealingLR(optimizer, warmup_epochs = 1, max_epochs = 512)\n",
        "#         return [optimizer], [{\"scheduler\": scheduler, \"interval\": \"epoch\"}] #optimizer\n",
        "\n",
        "#     def on_save_checkpoint(self, checkpoint):\n",
        "#         # Exclude teacher model's weights from checkpoint\n",
        "#         checkpoint['state_dict'] = {k: v for k, v in checkpoint['state_dict'].items() if 'teacher_model' not in k}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [],
      "source": [
        "# device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "# distill_model = ContrastiveModel.load_from_checkpoint(\"./logs/KD_EMBEDDING_CD_ONLY_VIGOR_CROSS/version_0/checkpoints/tinyvit.ckpt\")\n",
        "# distill_model = distill_model.to(device)\n",
        "# distill_model.eval()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [],
      "source": [
        "class TimmModel(nn.Module):\n",
        "\n",
        "    def __init__(self, \n",
        "                 model_name,\n",
        "                 pretrained=True,\n",
        "                 img_size=383):\n",
        "                 \n",
        "        super(TimmModel, self).__init__()\n",
        "        \n",
        "        self.img_size = img_size\n",
        "        \n",
        "        if \"vit\" in model_name:\n",
        "            # automatically change interpolate pos-encoding to img_size\n",
        "            self.model = timm.create_model(model_name, pretrained=pretrained, num_classes=0, img_size=img_size) \n",
        "        else:\n",
        "            self.model = timm.create_model(model_name, pretrained=pretrained, num_classes=0)\n",
        "        \n",
        "        self.logit_scale = torch.nn.Parameter(torch.ones([]) * np.log(1 / 0.07))\n",
        "        \n",
        "        \n",
        "    def get_config(self,):\n",
        "        data_config = timm.data.resolve_model_data_config(self.model)\n",
        "        return data_config\n",
        "    \n",
        "    \n",
        "    def set_grad_checkpointing(self, enable=True):\n",
        "        self.model.set_grad_checkpointing(enable)\n",
        "\n",
        "        \n",
        "    def forward(self, img1, img2=None):\n",
        "        \n",
        "        if img2 is not None:\n",
        "       \n",
        "            image_features1 = self.model(img1)     \n",
        "            image_features2 = self.model(img2)\n",
        "            \n",
        "            return image_features1, image_features2\n",
        "              \n",
        "        else:\n",
        "            image_features = self.model(img1)\n",
        "             \n",
        "            return image_features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/cvgl/anaconda3/envs/haad/lib/python3.11/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
            "  return self.fget.__get__(instance, owner)()\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "TimmModel(\n",
              "  (model): ConvNeXt(\n",
              "    (stem): Sequential(\n",
              "      (0): Conv2d(3, 128, kernel_size=(4, 4), stride=(4, 4))\n",
              "      (1): LayerNorm2d((128,), eps=1e-06, elementwise_affine=True)\n",
              "    )\n",
              "    (stages): Sequential(\n",
              "      (0): ConvNeXtStage(\n",
              "        (downsample): Identity()\n",
              "        (blocks): Sequential(\n",
              "          (0): ConvNeXtBlock(\n",
              "            (conv_dw): Conv2d(128, 128, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=128)\n",
              "            (norm): LayerNorm((128,), eps=1e-06, elementwise_affine=True)\n",
              "            (mlp): Mlp(\n",
              "              (fc1): Linear(in_features=128, out_features=512, bias=True)\n",
              "              (act): GELU()\n",
              "              (drop1): Dropout(p=0.0, inplace=False)\n",
              "              (norm): Identity()\n",
              "              (fc2): Linear(in_features=512, out_features=128, bias=True)\n",
              "              (drop2): Dropout(p=0.0, inplace=False)\n",
              "            )\n",
              "            (shortcut): Identity()\n",
              "            (drop_path): Identity()\n",
              "          )\n",
              "          (1): ConvNeXtBlock(\n",
              "            (conv_dw): Conv2d(128, 128, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=128)\n",
              "            (norm): LayerNorm((128,), eps=1e-06, elementwise_affine=True)\n",
              "            (mlp): Mlp(\n",
              "              (fc1): Linear(in_features=128, out_features=512, bias=True)\n",
              "              (act): GELU()\n",
              "              (drop1): Dropout(p=0.0, inplace=False)\n",
              "              (norm): Identity()\n",
              "              (fc2): Linear(in_features=512, out_features=128, bias=True)\n",
              "              (drop2): Dropout(p=0.0, inplace=False)\n",
              "            )\n",
              "            (shortcut): Identity()\n",
              "            (drop_path): Identity()\n",
              "          )\n",
              "          (2): ConvNeXtBlock(\n",
              "            (conv_dw): Conv2d(128, 128, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=128)\n",
              "            (norm): LayerNorm((128,), eps=1e-06, elementwise_affine=True)\n",
              "            (mlp): Mlp(\n",
              "              (fc1): Linear(in_features=128, out_features=512, bias=True)\n",
              "              (act): GELU()\n",
              "              (drop1): Dropout(p=0.0, inplace=False)\n",
              "              (norm): Identity()\n",
              "              (fc2): Linear(in_features=512, out_features=128, bias=True)\n",
              "              (drop2): Dropout(p=0.0, inplace=False)\n",
              "            )\n",
              "            (shortcut): Identity()\n",
              "            (drop_path): Identity()\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (1): ConvNeXtStage(\n",
              "        (downsample): Sequential(\n",
              "          (0): LayerNorm2d((128,), eps=1e-06, elementwise_affine=True)\n",
              "          (1): Conv2d(128, 256, kernel_size=(2, 2), stride=(2, 2))\n",
              "        )\n",
              "        (blocks): Sequential(\n",
              "          (0): ConvNeXtBlock(\n",
              "            (conv_dw): Conv2d(256, 256, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=256)\n",
              "            (norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)\n",
              "            (mlp): Mlp(\n",
              "              (fc1): Linear(in_features=256, out_features=1024, bias=True)\n",
              "              (act): GELU()\n",
              "              (drop1): Dropout(p=0.0, inplace=False)\n",
              "              (norm): Identity()\n",
              "              (fc2): Linear(in_features=1024, out_features=256, bias=True)\n",
              "              (drop2): Dropout(p=0.0, inplace=False)\n",
              "            )\n",
              "            (shortcut): Identity()\n",
              "            (drop_path): Identity()\n",
              "          )\n",
              "          (1): ConvNeXtBlock(\n",
              "            (conv_dw): Conv2d(256, 256, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=256)\n",
              "            (norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)\n",
              "            (mlp): Mlp(\n",
              "              (fc1): Linear(in_features=256, out_features=1024, bias=True)\n",
              "              (act): GELU()\n",
              "              (drop1): Dropout(p=0.0, inplace=False)\n",
              "              (norm): Identity()\n",
              "              (fc2): Linear(in_features=1024, out_features=256, bias=True)\n",
              "              (drop2): Dropout(p=0.0, inplace=False)\n",
              "            )\n",
              "            (shortcut): Identity()\n",
              "            (drop_path): Identity()\n",
              "          )\n",
              "          (2): ConvNeXtBlock(\n",
              "            (conv_dw): Conv2d(256, 256, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=256)\n",
              "            (norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)\n",
              "            (mlp): Mlp(\n",
              "              (fc1): Linear(in_features=256, out_features=1024, bias=True)\n",
              "              (act): GELU()\n",
              "              (drop1): Dropout(p=0.0, inplace=False)\n",
              "              (norm): Identity()\n",
              "              (fc2): Linear(in_features=1024, out_features=256, bias=True)\n",
              "              (drop2): Dropout(p=0.0, inplace=False)\n",
              "            )\n",
              "            (shortcut): Identity()\n",
              "            (drop_path): Identity()\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (2): ConvNeXtStage(\n",
              "        (downsample): Sequential(\n",
              "          (0): LayerNorm2d((256,), eps=1e-06, elementwise_affine=True)\n",
              "          (1): Conv2d(256, 512, kernel_size=(2, 2), stride=(2, 2))\n",
              "        )\n",
              "        (blocks): Sequential(\n",
              "          (0): ConvNeXtBlock(\n",
              "            (conv_dw): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n",
              "            (norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
              "            (mlp): Mlp(\n",
              "              (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
              "              (act): GELU()\n",
              "              (drop1): Dropout(p=0.0, inplace=False)\n",
              "              (norm): Identity()\n",
              "              (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
              "              (drop2): Dropout(p=0.0, inplace=False)\n",
              "            )\n",
              "            (shortcut): Identity()\n",
              "            (drop_path): Identity()\n",
              "          )\n",
              "          (1): ConvNeXtBlock(\n",
              "            (conv_dw): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n",
              "            (norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
              "            (mlp): Mlp(\n",
              "              (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
              "              (act): GELU()\n",
              "              (drop1): Dropout(p=0.0, inplace=False)\n",
              "              (norm): Identity()\n",
              "              (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
              "              (drop2): Dropout(p=0.0, inplace=False)\n",
              "            )\n",
              "            (shortcut): Identity()\n",
              "            (drop_path): Identity()\n",
              "          )\n",
              "          (2): ConvNeXtBlock(\n",
              "            (conv_dw): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n",
              "            (norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
              "            (mlp): Mlp(\n",
              "              (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
              "              (act): GELU()\n",
              "              (drop1): Dropout(p=0.0, inplace=False)\n",
              "              (norm): Identity()\n",
              "              (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
              "              (drop2): Dropout(p=0.0, inplace=False)\n",
              "            )\n",
              "            (shortcut): Identity()\n",
              "            (drop_path): Identity()\n",
              "          )\n",
              "          (3): ConvNeXtBlock(\n",
              "            (conv_dw): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n",
              "            (norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
              "            (mlp): Mlp(\n",
              "              (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
              "              (act): GELU()\n",
              "              (drop1): Dropout(p=0.0, inplace=False)\n",
              "              (norm): Identity()\n",
              "              (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
              "              (drop2): Dropout(p=0.0, inplace=False)\n",
              "            )\n",
              "            (shortcut): Identity()\n",
              "            (drop_path): Identity()\n",
              "          )\n",
              "          (4): ConvNeXtBlock(\n",
              "            (conv_dw): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n",
              "            (norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
              "            (mlp): Mlp(\n",
              "              (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
              "              (act): GELU()\n",
              "              (drop1): Dropout(p=0.0, inplace=False)\n",
              "              (norm): Identity()\n",
              "              (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
              "              (drop2): Dropout(p=0.0, inplace=False)\n",
              "            )\n",
              "            (shortcut): Identity()\n",
              "            (drop_path): Identity()\n",
              "          )\n",
              "          (5): ConvNeXtBlock(\n",
              "            (conv_dw): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n",
              "            (norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
              "            (mlp): Mlp(\n",
              "              (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
              "              (act): GELU()\n",
              "              (drop1): Dropout(p=0.0, inplace=False)\n",
              "              (norm): Identity()\n",
              "              (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
              "              (drop2): Dropout(p=0.0, inplace=False)\n",
              "            )\n",
              "            (shortcut): Identity()\n",
              "            (drop_path): Identity()\n",
              "          )\n",
              "          (6): ConvNeXtBlock(\n",
              "            (conv_dw): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n",
              "            (norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
              "            (mlp): Mlp(\n",
              "              (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
              "              (act): GELU()\n",
              "              (drop1): Dropout(p=0.0, inplace=False)\n",
              "              (norm): Identity()\n",
              "              (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
              "              (drop2): Dropout(p=0.0, inplace=False)\n",
              "            )\n",
              "            (shortcut): Identity()\n",
              "            (drop_path): Identity()\n",
              "          )\n",
              "          (7): ConvNeXtBlock(\n",
              "            (conv_dw): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n",
              "            (norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
              "            (mlp): Mlp(\n",
              "              (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
              "              (act): GELU()\n",
              "              (drop1): Dropout(p=0.0, inplace=False)\n",
              "              (norm): Identity()\n",
              "              (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
              "              (drop2): Dropout(p=0.0, inplace=False)\n",
              "            )\n",
              "            (shortcut): Identity()\n",
              "            (drop_path): Identity()\n",
              "          )\n",
              "          (8): ConvNeXtBlock(\n",
              "            (conv_dw): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n",
              "            (norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
              "            (mlp): Mlp(\n",
              "              (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
              "              (act): GELU()\n",
              "              (drop1): Dropout(p=0.0, inplace=False)\n",
              "              (norm): Identity()\n",
              "              (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
              "              (drop2): Dropout(p=0.0, inplace=False)\n",
              "            )\n",
              "            (shortcut): Identity()\n",
              "            (drop_path): Identity()\n",
              "          )\n",
              "          (9): ConvNeXtBlock(\n",
              "            (conv_dw): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n",
              "            (norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
              "            (mlp): Mlp(\n",
              "              (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
              "              (act): GELU()\n",
              "              (drop1): Dropout(p=0.0, inplace=False)\n",
              "              (norm): Identity()\n",
              "              (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
              "              (drop2): Dropout(p=0.0, inplace=False)\n",
              "            )\n",
              "            (shortcut): Identity()\n",
              "            (drop_path): Identity()\n",
              "          )\n",
              "          (10): ConvNeXtBlock(\n",
              "            (conv_dw): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n",
              "            (norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
              "            (mlp): Mlp(\n",
              "              (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
              "              (act): GELU()\n",
              "              (drop1): Dropout(p=0.0, inplace=False)\n",
              "              (norm): Identity()\n",
              "              (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
              "              (drop2): Dropout(p=0.0, inplace=False)\n",
              "            )\n",
              "            (shortcut): Identity()\n",
              "            (drop_path): Identity()\n",
              "          )\n",
              "          (11): ConvNeXtBlock(\n",
              "            (conv_dw): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n",
              "            (norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
              "            (mlp): Mlp(\n",
              "              (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
              "              (act): GELU()\n",
              "              (drop1): Dropout(p=0.0, inplace=False)\n",
              "              (norm): Identity()\n",
              "              (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
              "              (drop2): Dropout(p=0.0, inplace=False)\n",
              "            )\n",
              "            (shortcut): Identity()\n",
              "            (drop_path): Identity()\n",
              "          )\n",
              "          (12): ConvNeXtBlock(\n",
              "            (conv_dw): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n",
              "            (norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
              "            (mlp): Mlp(\n",
              "              (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
              "              (act): GELU()\n",
              "              (drop1): Dropout(p=0.0, inplace=False)\n",
              "              (norm): Identity()\n",
              "              (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
              "              (drop2): Dropout(p=0.0, inplace=False)\n",
              "            )\n",
              "            (shortcut): Identity()\n",
              "            (drop_path): Identity()\n",
              "          )\n",
              "          (13): ConvNeXtBlock(\n",
              "            (conv_dw): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n",
              "            (norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
              "            (mlp): Mlp(\n",
              "              (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
              "              (act): GELU()\n",
              "              (drop1): Dropout(p=0.0, inplace=False)\n",
              "              (norm): Identity()\n",
              "              (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
              "              (drop2): Dropout(p=0.0, inplace=False)\n",
              "            )\n",
              "            (shortcut): Identity()\n",
              "            (drop_path): Identity()\n",
              "          )\n",
              "          (14): ConvNeXtBlock(\n",
              "            (conv_dw): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n",
              "            (norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
              "            (mlp): Mlp(\n",
              "              (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
              "              (act): GELU()\n",
              "              (drop1): Dropout(p=0.0, inplace=False)\n",
              "              (norm): Identity()\n",
              "              (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
              "              (drop2): Dropout(p=0.0, inplace=False)\n",
              "            )\n",
              "            (shortcut): Identity()\n",
              "            (drop_path): Identity()\n",
              "          )\n",
              "          (15): ConvNeXtBlock(\n",
              "            (conv_dw): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n",
              "            (norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
              "            (mlp): Mlp(\n",
              "              (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
              "              (act): GELU()\n",
              "              (drop1): Dropout(p=0.0, inplace=False)\n",
              "              (norm): Identity()\n",
              "              (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
              "              (drop2): Dropout(p=0.0, inplace=False)\n",
              "            )\n",
              "            (shortcut): Identity()\n",
              "            (drop_path): Identity()\n",
              "          )\n",
              "          (16): ConvNeXtBlock(\n",
              "            (conv_dw): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n",
              "            (norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
              "            (mlp): Mlp(\n",
              "              (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
              "              (act): GELU()\n",
              "              (drop1): Dropout(p=0.0, inplace=False)\n",
              "              (norm): Identity()\n",
              "              (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
              "              (drop2): Dropout(p=0.0, inplace=False)\n",
              "            )\n",
              "            (shortcut): Identity()\n",
              "            (drop_path): Identity()\n",
              "          )\n",
              "          (17): ConvNeXtBlock(\n",
              "            (conv_dw): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n",
              "            (norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
              "            (mlp): Mlp(\n",
              "              (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
              "              (act): GELU()\n",
              "              (drop1): Dropout(p=0.0, inplace=False)\n",
              "              (norm): Identity()\n",
              "              (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
              "              (drop2): Dropout(p=0.0, inplace=False)\n",
              "            )\n",
              "            (shortcut): Identity()\n",
              "            (drop_path): Identity()\n",
              "          )\n",
              "          (18): ConvNeXtBlock(\n",
              "            (conv_dw): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n",
              "            (norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
              "            (mlp): Mlp(\n",
              "              (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
              "              (act): GELU()\n",
              "              (drop1): Dropout(p=0.0, inplace=False)\n",
              "              (norm): Identity()\n",
              "              (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
              "              (drop2): Dropout(p=0.0, inplace=False)\n",
              "            )\n",
              "            (shortcut): Identity()\n",
              "            (drop_path): Identity()\n",
              "          )\n",
              "          (19): ConvNeXtBlock(\n",
              "            (conv_dw): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n",
              "            (norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
              "            (mlp): Mlp(\n",
              "              (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
              "              (act): GELU()\n",
              "              (drop1): Dropout(p=0.0, inplace=False)\n",
              "              (norm): Identity()\n",
              "              (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
              "              (drop2): Dropout(p=0.0, inplace=False)\n",
              "            )\n",
              "            (shortcut): Identity()\n",
              "            (drop_path): Identity()\n",
              "          )\n",
              "          (20): ConvNeXtBlock(\n",
              "            (conv_dw): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n",
              "            (norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
              "            (mlp): Mlp(\n",
              "              (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
              "              (act): GELU()\n",
              "              (drop1): Dropout(p=0.0, inplace=False)\n",
              "              (norm): Identity()\n",
              "              (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
              "              (drop2): Dropout(p=0.0, inplace=False)\n",
              "            )\n",
              "            (shortcut): Identity()\n",
              "            (drop_path): Identity()\n",
              "          )\n",
              "          (21): ConvNeXtBlock(\n",
              "            (conv_dw): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n",
              "            (norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
              "            (mlp): Mlp(\n",
              "              (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
              "              (act): GELU()\n",
              "              (drop1): Dropout(p=0.0, inplace=False)\n",
              "              (norm): Identity()\n",
              "              (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
              "              (drop2): Dropout(p=0.0, inplace=False)\n",
              "            )\n",
              "            (shortcut): Identity()\n",
              "            (drop_path): Identity()\n",
              "          )\n",
              "          (22): ConvNeXtBlock(\n",
              "            (conv_dw): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n",
              "            (norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
              "            (mlp): Mlp(\n",
              "              (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
              "              (act): GELU()\n",
              "              (drop1): Dropout(p=0.0, inplace=False)\n",
              "              (norm): Identity()\n",
              "              (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
              "              (drop2): Dropout(p=0.0, inplace=False)\n",
              "            )\n",
              "            (shortcut): Identity()\n",
              "            (drop_path): Identity()\n",
              "          )\n",
              "          (23): ConvNeXtBlock(\n",
              "            (conv_dw): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n",
              "            (norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
              "            (mlp): Mlp(\n",
              "              (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
              "              (act): GELU()\n",
              "              (drop1): Dropout(p=0.0, inplace=False)\n",
              "              (norm): Identity()\n",
              "              (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
              "              (drop2): Dropout(p=0.0, inplace=False)\n",
              "            )\n",
              "            (shortcut): Identity()\n",
              "            (drop_path): Identity()\n",
              "          )\n",
              "          (24): ConvNeXtBlock(\n",
              "            (conv_dw): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n",
              "            (norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
              "            (mlp): Mlp(\n",
              "              (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
              "              (act): GELU()\n",
              "              (drop1): Dropout(p=0.0, inplace=False)\n",
              "              (norm): Identity()\n",
              "              (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
              "              (drop2): Dropout(p=0.0, inplace=False)\n",
              "            )\n",
              "            (shortcut): Identity()\n",
              "            (drop_path): Identity()\n",
              "          )\n",
              "          (25): ConvNeXtBlock(\n",
              "            (conv_dw): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n",
              "            (norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
              "            (mlp): Mlp(\n",
              "              (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
              "              (act): GELU()\n",
              "              (drop1): Dropout(p=0.0, inplace=False)\n",
              "              (norm): Identity()\n",
              "              (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
              "              (drop2): Dropout(p=0.0, inplace=False)\n",
              "            )\n",
              "            (shortcut): Identity()\n",
              "            (drop_path): Identity()\n",
              "          )\n",
              "          (26): ConvNeXtBlock(\n",
              "            (conv_dw): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n",
              "            (norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
              "            (mlp): Mlp(\n",
              "              (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
              "              (act): GELU()\n",
              "              (drop1): Dropout(p=0.0, inplace=False)\n",
              "              (norm): Identity()\n",
              "              (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
              "              (drop2): Dropout(p=0.0, inplace=False)\n",
              "            )\n",
              "            (shortcut): Identity()\n",
              "            (drop_path): Identity()\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (3): ConvNeXtStage(\n",
              "        (downsample): Sequential(\n",
              "          (0): LayerNorm2d((512,), eps=1e-06, elementwise_affine=True)\n",
              "          (1): Conv2d(512, 1024, kernel_size=(2, 2), stride=(2, 2))\n",
              "        )\n",
              "        (blocks): Sequential(\n",
              "          (0): ConvNeXtBlock(\n",
              "            (conv_dw): Conv2d(1024, 1024, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=1024)\n",
              "            (norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "            (mlp): Mlp(\n",
              "              (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "              (act): GELU()\n",
              "              (drop1): Dropout(p=0.0, inplace=False)\n",
              "              (norm): Identity()\n",
              "              (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "              (drop2): Dropout(p=0.0, inplace=False)\n",
              "            )\n",
              "            (shortcut): Identity()\n",
              "            (drop_path): Identity()\n",
              "          )\n",
              "          (1): ConvNeXtBlock(\n",
              "            (conv_dw): Conv2d(1024, 1024, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=1024)\n",
              "            (norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "            (mlp): Mlp(\n",
              "              (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "              (act): GELU()\n",
              "              (drop1): Dropout(p=0.0, inplace=False)\n",
              "              (norm): Identity()\n",
              "              (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "              (drop2): Dropout(p=0.0, inplace=False)\n",
              "            )\n",
              "            (shortcut): Identity()\n",
              "            (drop_path): Identity()\n",
              "          )\n",
              "          (2): ConvNeXtBlock(\n",
              "            (conv_dw): Conv2d(1024, 1024, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=1024)\n",
              "            (norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "            (mlp): Mlp(\n",
              "              (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "              (act): GELU()\n",
              "              (drop1): Dropout(p=0.0, inplace=False)\n",
              "              (norm): Identity()\n",
              "              (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "              (drop2): Dropout(p=0.0, inplace=False)\n",
              "            )\n",
              "            (shortcut): Identity()\n",
              "            (drop_path): Identity()\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (norm_pre): Identity()\n",
              "    (head): NormMlpClassifierHead(\n",
              "      (global_pool): SelectAdaptivePool2d(pool_type=avg, flatten=Identity())\n",
              "      (norm): LayerNorm2d((1024,), eps=1e-06, elementwise_affine=True)\n",
              "      (flatten): Flatten(start_dim=1, end_dim=-1)\n",
              "      (pre_logits): Identity()\n",
              "      (drop): Dropout(p=0.0, inplace=False)\n",
              "      (fc): Identity()\n",
              "    )\n",
              "  )\n",
              ")"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model = TimmModel('convnext_base.fb_in22k_ft_in1k_384', pretrained=True, img_size= 384)\n",
        "model.load_state_dict(torch.load(\"pretrained/vigor_cross/convnext_base.fb_in22k_ft_in1k_384/weights_e40_0.6109.pth\", weights_only=True))\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = model.to(device)\n",
        "model.eval()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Scr3JOak-Are",
        "outputId": "e86d566c-f58c-4c86-8115-4f35872c665a"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|| 839/839 [07:57<00:00,  1.76it/s]\n",
            "100%|| 728/728 [03:31<00:00,  3.45it/s]\n"
          ]
        }
      ],
      "source": [
        "def process_embeddings(sat_loader, street_loader, model, output_prefix, device):\n",
        "    all_street_embed = []\n",
        "    all_sat_embed = []\n",
        "    all_sat_ids = []\n",
        "    all_street_ids = []\n",
        "\n",
        "    with autocast():\n",
        "        with torch.no_grad():\n",
        "            # Street Image Embeddings\n",
        "            for (street_keys, street_images) in tqdm(street_loader):\n",
        "                # street_features = model.street_linear(model.street_model(street_images.to(device)))\n",
        "                street_features = model(street_images.to(device))\n",
        "                all_street_embed.append(street_features.detach().cpu())\n",
        "                \n",
        "                all_street_ids.extend(street_keys.tolist())\n",
        "\n",
        "            # Satellite Image Embeddings\n",
        "            for (sat_keys, sat_images) in tqdm(sat_loader):\n",
        "                # sat_features = model.sat_linear(model.sat_model(sat_images.to(device)))\n",
        "                sat_features = model(sat_images.to(device))\n",
        "                all_sat_embed.append(sat_features.detach().cpu())\n",
        "                all_sat_ids.extend(sat_keys.tolist())\n",
        "\n",
        "    # Save the embeddings\n",
        "    joblib.dump(torch.vstack(all_street_embed), f'{output_prefix}_street_embed.joblib')\n",
        "    joblib.dump(torch.vstack(all_sat_embed), f'{output_prefix}_sat_embed.joblib')\n",
        "    joblib.dump(all_street_ids, f'{output_prefix}_all_street_ids.joblib')\n",
        "    joblib.dump(all_sat_ids, f'{output_prefix}_all_sat_ids.joblib')\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "process_embeddings(\n",
        "    sat_loader= reference_loader,\n",
        "    street_loader= query_loader,\n",
        "    model=  model, # distill_model,\n",
        "    output_prefix='MB1/vigor_cross_test',\n",
        "    device=device\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load the stored embeddings and IDs for s2d (satellite to drone)\n",
        "query_features = joblib.load(open(\"MB1/vigor_cross_test_street_embed.joblib\", 'rb'))\n",
        "reference_features = joblib.load(open(\"MB1/vigor_cross_test_sat_embed.joblib\", 'rb'))\n",
        "query_ids = joblib.load(open('MB1/vigor_cross_test_all_street_ids.joblib', 'rb'))\n",
        "reference_ids = joblib.load(open('MB1/vigor_cross_test_all_sat_ids.joblib', 'rb'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Normalizing features\n",
        "query_features = F.normalize(query_features, dim=-1)\n",
        "reference_features = F.normalize(reference_features, dim=-1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "import time\n",
        "import copy\n",
        "\n",
        "def calculate_scores(query_features, reference_features, query_labels, reference_labels, step_size=1000, ranks=[1,5,10]):\n",
        "\n",
        "    topk = copy.deepcopy(ranks)\n",
        "    Q = len(query_features)\n",
        "    R = len(reference_features)\n",
        "    \n",
        "    steps = Q // step_size + 1\n",
        "    \n",
        "    query_labels_np = np.array(query_labels)\n",
        "    reference_labels_np = np.array(reference_labels)\n",
        "    \n",
        "    #print(query_labels_np)\n",
        "    \n",
        "    ref2index = dict()\n",
        "    for i, idx in enumerate(reference_labels_np):\n",
        "        ref2index[idx] = i\n",
        "    \n",
        "    #print(ref2index)\n",
        "    \n",
        "    similarity = []\n",
        "    \n",
        "    for i in range(steps):\n",
        "        \n",
        "        start = step_size * i\n",
        "        \n",
        "        end = start + step_size\n",
        "          \n",
        "        sim_tmp = query_features[start:end] @ reference_features.T\n",
        "        \n",
        "        similarity.append(sim_tmp.cpu())\n",
        "     \n",
        "    # matrix Q x R\n",
        "    similarity = torch.cat(similarity, dim=0)\n",
        "    \n",
        "\n",
        "    topk.append(R//100)\n",
        "    \n",
        "    results = np.zeros([len(topk)])\n",
        "    \n",
        "    hit_rate = 0.0\n",
        "    \n",
        "    bar = tqdm(range(Q))\n",
        "    \n",
        "    for i in bar:\n",
        "        \n",
        "        # similiarity value of gt reference\n",
        "        gt_sim = similarity[i, ref2index[query_labels_np[i][0]]]\n",
        "        \n",
        "        # number of references with higher similiarity as gt\n",
        "        higher_sim = similarity[i,:] > gt_sim\n",
        "        \n",
        "         \n",
        "        ranking = higher_sim.sum()\n",
        "        for j, k in enumerate(topk):\n",
        "            if ranking < k:\n",
        "                results[j] += 1.\n",
        "                        \n",
        "        # mask for semi pos\n",
        "        mask = torch.ones(R)\n",
        "        for near_pos in query_labels_np[i][1:]:\n",
        "            mask[ref2index[near_pos]] = 0\n",
        "        \n",
        "        # calculate hit rate\n",
        "        hit = (higher_sim * mask).sum()\n",
        "        if hit < 1:\n",
        "            hit_rate += 1.0\n",
        "                \n",
        "    \n",
        "    results = results/ Q * 100.\n",
        "    hit_rate = hit_rate / Q * 100\n",
        "    \n",
        "    bar.close()\n",
        "    \n",
        "    # wait to close pbar\n",
        "    time.sleep(0.1)\n",
        "    \n",
        "    string = []\n",
        "    for i in range(len(topk)-1):\n",
        "        \n",
        "        string.append('Recall@{}: {:.4f}'.format(topk[i], results[i]))\n",
        "        \n",
        "    string.append('Recall@top1: {:.4f}'.format(results[-1]))\n",
        "    string.append('Hit_Rate: {:.4f}'.format(hit_rate))             \n",
        "        \n",
        "    print(' - '.join(string)) \n",
        "\n",
        "    return results[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|| 53694/53694 [02:24<00:00, 370.93it/s] \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Recall@1: 61.7797 - Recall@5: 83.4879 - Recall@10: 88.0210 - Recall@top1: 98.1897 - Hit_Rate: 69.9166\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "61.779714679480016"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "calculate_scores(query_features, reference_features, query_ids, reference_ids)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "haad",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
